{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class 를 이용하여 data-01.csv 선형회귀 구현\n",
    "## 멀티 오브젝트를 통한 테스트 다양성 시도 (reset 불필요)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "class LinearRegressionTest:\n",
    "    \n",
    "    # constructor\n",
    "    def __init__(self, xdata, tdata, learning_rate, iteration_count):            \n",
    "        \n",
    "        self.learning_rate = learning_rate\n",
    "        self.iteration_count = iteration_count\n",
    "        \n",
    "        self.W = np.random.rand(self.xdata.shape[1], 1) # 입력 xdata가 이미 행렬이라 가정한 구현\n",
    "        self.b = np.random.rand(1)\n",
    "        \n",
    "        print(\"LinearRegressionTest Object is created\")\n",
    "        \n",
    "    \n",
    "    # obtain current W and current b\n",
    "    def getW_b(self):\n",
    "        \n",
    "        return self.W, self.b\n",
    "    \n",
    "    \n",
    "    # loss function\n",
    "    def loss_func(self):\n",
    "        \n",
    "        y = np.dot(self.xdata, self.W) + self.b\n",
    "    \n",
    "        return ( np.sum( (self.tdata - y)**2 ) ) / ( len(self.xdata) )\n",
    "        \n",
    "    \n",
    "    # display current error value\n",
    "    def error_val(self):\n",
    "        \n",
    "        y = np.dot(self.xdata, self.W) + self.b\n",
    "    \n",
    "        return ( np.sum( (self.tdata - y)**2 ) ) / ( len(self.xdata) )\n",
    "    \n",
    "    \n",
    "    # predict method\n",
    "    def predict(self, test_data):\n",
    "        \n",
    "        y = np.dot(test_data, self.W) + self.b\n",
    "        \n",
    "        return y\n",
    "    \n",
    "    \n",
    "    # train method\n",
    "    def train(self):\n",
    "    \n",
    "        f = lambda x : self.loss_func()\n",
    "\n",
    "        print(\"Initial error value = \", self.error_val(), \"Initial W = \", self.W, \"\\n\", \", b = \", self.b )\n",
    "\n",
    "        start_time = datetime.now()\n",
    "        \n",
    "        for step in  range(self.iteration_count):  \n",
    "    \n",
    "            self.W -= self.learning_rate * numerical_derivative(f, self.W)\n",
    "    \n",
    "            self.b -= self.learning_rate * numerical_derivative(f, self.b)\n",
    "    \n",
    "            if (step % 400 == 0):\n",
    "                print(\"step = \", step, \"error value = \", self.error_val(), \"W = \", self.W, \", b = \", self.b )\n",
    "                \n",
    "        end_time = datetime.now()\n",
    "        \n",
    "        print(\"\")\n",
    "        print(\"Elapsed Time => \", end_time - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def numerical_derivative(f, x):\n",
    "    delta_x = 1e-4 # 0.0001\n",
    "    grad = np.zeros_like(x)\n",
    "    \n",
    "    it = np.nditer(x, flags=['multi_index'], op_flags=['readwrite'])\n",
    "    \n",
    "    while not it.finished:\n",
    "        idx = it.multi_index        \n",
    "        tmp_val = x[idx]\n",
    "        x[idx] = float(tmp_val) + delta_x\n",
    "        fx1 = f(x) # f(x+delta_x)\n",
    "        \n",
    "        x[idx] = tmp_val - delta_x \n",
    "        fx2 = f(x) # f(x-delta_x)\n",
    "        grad[idx] = (fx1 - fx2) / (2*delta_x)\n",
    "        \n",
    "        x[idx] = tmp_val \n",
    "        it.iternext()   \n",
    "        \n",
    "    return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_data.ndim =  2 , x_data.shape =  (25, 3)\n",
      "t_data.ndim =  2 , t_data.shape =  (25, 1)\n"
     ]
    }
   ],
   "source": [
    "loaded_data = np.loadtxt('./data-01.csv', delimiter=',', dtype=np.float32)\n",
    "\n",
    "x_data = loaded_data[ :, 0:-1]\n",
    "t_data = loaded_data[ :, [-1]]\n",
    "\n",
    "# 데이터 차원 및 shape 확인\n",
    "print(\"x_data.ndim = \", x_data.ndim, \", x_data.shape = \", x_data.shape)\n",
    "print(\"t_data.ndim = \", t_data.ndim, \", t_data.shape = \", t_data.shape) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### learning_rate = 1e-5,  반복횟수 10,000번 수행하는 obj1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearRegressionTest Object is created\n",
      "Initial error value =  272.1053696047822 Initial W =  [[0.39554594]\n",
      " [0.94924778]\n",
      " [0.48519548]] \n",
      " , b =  [0.04161918]\n",
      "step =  0 error value =  112.46195312700404 W =  [[0.42094473]\n",
      " [0.97459593]\n",
      " [0.51161186]] , b =  [0.04181077]\n",
      "step =  400 error value =  15.02356658868754 W =  [[0.44833759]\n",
      " [0.93277868]\n",
      " [0.64356154]] , b =  [0.04205359]\n",
      "step =  800 error value =  12.364477637612067 W =  [[0.43777069]\n",
      " [0.86481718]\n",
      " [0.72024544]] , b =  [0.04190069]\n",
      "step =  1200 error value =  10.499521051754567 W =  [[0.42849932]\n",
      " [0.80815483]\n",
      " [0.78462965]] , b =  [0.04166515]\n",
      "step =  1600 error value =  9.191316546215482 W =  [[0.42035293]\n",
      " [0.76092917]\n",
      " [0.83869977]] , b =  [0.04136019]\n",
      "step =  2000 error value =  8.273478043030256 W =  [[0.4131849 ]\n",
      " [0.72158324]\n",
      " [0.88411962]] , b =  [0.04099695]\n",
      "step =  2400 error value =  7.629374453318411 W =  [[0.40686902]\n",
      " [0.68881561]\n",
      " [0.92228353]] , b =  [0.04058475]\n",
      "step =  2800 error value =  7.177245778394409 W =  [[0.40129647]\n",
      " [0.66153855]\n",
      " [0.95436008]] , b =  [0.0401314]\n",
      "step =  3200 error value =  6.859772634587542 W =  [[0.39637334]\n",
      " [0.63884308]\n",
      " [0.98132875]] , b =  [0.03964347]\n",
      "step =  3600 error value =  6.636766508437656 W =  [[0.39201838]\n",
      " [0.61996969]\n",
      " [1.00401061]] , b =  [0.03912648]\n",
      "step =  4000 error value =  6.480046892065485 W =  [[0.38816129]\n",
      " [0.60428386]\n",
      " [1.023094  ]] , b =  [0.03858504]\n",
      "step =  4400 error value =  6.369850921509785 W =  [[0.38474109]\n",
      " [0.59125555]\n",
      " [1.03915609]] , b =  [0.03802305]\n",
      "step =  4800 error value =  6.292316971200104 W =  [[0.3817048 ]\n",
      " [0.58044213]\n",
      " [1.05268087]] , b =  [0.03744376]\n",
      "step =  5200 error value =  6.237720879483731 W =  [[0.37900637]\n",
      " [0.57147399]\n",
      " [1.06407426]] , b =  [0.03684992]\n",
      "step =  5600 error value =  6.1992396345363785 W =  [[0.37660567]\n",
      " [0.56404256]\n",
      " [1.07367676]] , b =  [0.03624382]\n",
      "step =  6000 error value =  6.1720847281476425 W =  [[0.37446768]\n",
      " [0.55789031]\n",
      " [1.08177403]] , b =  [0.03562741]\n",
      "step =  6400 error value =  6.152894599187035 W =  [[0.37256183]\n",
      " [0.55280235]\n",
      " [1.08860577]] , b =  [0.03500231]\n",
      "step =  6800 error value =  6.139308673716434 W =  [[0.37086133]\n",
      " [0.54859942]\n",
      " [1.09437316]] , b =  [0.03436989]\n",
      "step =  7200 error value =  6.129668693289815 W =  [[0.36934274]\n",
      " [0.54513202]\n",
      " [1.09924508]] , b =  [0.03373131]\n",
      "step =  7600 error value =  6.122809269925394 W =  [[0.36798547]\n",
      " [0.54227551]\n",
      " [1.10336331]] , b =  [0.03308753]\n",
      "step =  8000 error value =  6.1179109917620735 W =  [[0.36677143]\n",
      " [0.53992602]\n",
      " [1.10684694]] , b =  [0.03243936]\n",
      "step =  8400 error value =  6.114397382322414 W =  [[0.36568468]\n",
      " [0.53799701]\n",
      " [1.109796  ]] , b =  [0.03178751]\n",
      "step =  8800 error value =  6.111862608031071 W =  [[0.3647112 ]\n",
      " [0.53641641]\n",
      " [1.11229454]] , b =  [0.03113254]\n",
      "step =  9200 error value =  6.110020747509781 W =  [[0.3638386 ]\n",
      " [0.53512425]\n",
      " [1.11441322]] , b =  [0.03047495]\n",
      "step =  9600 error value =  6.108670182748419 W =  [[0.36305593]\n",
      " [0.53407062]\n",
      " [1.11621143]] , b =  [0.02981516]\n",
      "step =  10000 error value =  6.107668597294641 W =  [[0.36235352]\n",
      " [0.53321401]\n",
      " [1.11773912]] , b =  [0.0291535]\n",
      "\n",
      "Elapsed Time =>  0:00:01.634000\n"
     ]
    }
   ],
   "source": [
    "# LinearRegressionTest 객체를 만들기 위해 4개의 파라미터 필요\n",
    "# 1st : 입력데이터,  2nd : 정답데이터\n",
    "# 3rd : learning rate,  4th : iteration count\n",
    "obj1 = LinearRegressionTest(x_data, t_data, 1e-5, 10001)\n",
    "\n",
    "obj1.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([179.05634763])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = np.array([100, 98, 81])\n",
    "\n",
    "obj1.predict(test_data) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### learning_rate = 1e-3,  반복횟수 10,000번 수행하는 obj2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearRegressionTest Object is created\n",
      "Initial error value =  719.2685782355427 Initial W =  [[0.74535756]\n",
      " [0.03991242]\n",
      " [0.89921848]] \n",
      " , b =  [0.42328238]\n",
      "step =  0 error value =  1028396.2458336486 W =  [[4.98426132]\n",
      " [4.3262106 ]\n",
      " [5.27405744]] , b =  [-1.58855105]\n",
      "step =  400 error value =  4.936823732309998e+31 W =  [[1.05139060e+13]\n",
      " [3.25042048e+13]\n",
      " [4.34781583e+13]] , b =  [1.53142805e+08]\n",
      "step =  800 error value =  4.936823732309998e+31 W =  [[1.05139060e+13]\n",
      " [3.25042048e+13]\n",
      " [4.34781583e+13]] , b =  [1.53142805e+08]\n",
      "step =  1200 error value =  4.936823732309998e+31 W =  [[1.05139060e+13]\n",
      " [3.25042048e+13]\n",
      " [4.34781583e+13]] , b =  [1.53142805e+08]\n",
      "step =  1600 error value =  4.936823732309998e+31 W =  [[1.05139060e+13]\n",
      " [3.25042048e+13]\n",
      " [4.34781583e+13]] , b =  [1.53142805e+08]\n",
      "step =  2000 error value =  4.936823732309998e+31 W =  [[1.05139060e+13]\n",
      " [3.25042048e+13]\n",
      " [4.34781583e+13]] , b =  [1.53142805e+08]\n",
      "step =  2400 error value =  4.936823732309998e+31 W =  [[1.05139060e+13]\n",
      " [3.25042048e+13]\n",
      " [4.34781583e+13]] , b =  [1.53142805e+08]\n",
      "step =  2800 error value =  4.936823732309998e+31 W =  [[1.05139060e+13]\n",
      " [3.25042048e+13]\n",
      " [4.34781583e+13]] , b =  [1.53142805e+08]\n",
      "step =  3200 error value =  4.936823732309998e+31 W =  [[1.05139060e+13]\n",
      " [3.25042048e+13]\n",
      " [4.34781583e+13]] , b =  [1.53142805e+08]\n",
      "step =  3600 error value =  4.936823732309998e+31 W =  [[1.05139060e+13]\n",
      " [3.25042048e+13]\n",
      " [4.34781583e+13]] , b =  [1.53142805e+08]\n",
      "step =  4000 error value =  4.936823732309998e+31 W =  [[1.05139060e+13]\n",
      " [3.25042048e+13]\n",
      " [4.34781583e+13]] , b =  [1.53142805e+08]\n",
      "step =  4400 error value =  4.936823732309998e+31 W =  [[1.05139060e+13]\n",
      " [3.25042048e+13]\n",
      " [4.34781583e+13]] , b =  [1.53142805e+08]\n",
      "step =  4800 error value =  4.936823732309998e+31 W =  [[1.05139060e+13]\n",
      " [3.25042048e+13]\n",
      " [4.34781583e+13]] , b =  [1.53142805e+08]\n",
      "step =  5200 error value =  4.936823732309998e+31 W =  [[1.05139060e+13]\n",
      " [3.25042048e+13]\n",
      " [4.34781583e+13]] , b =  [1.53142805e+08]\n",
      "step =  5600 error value =  4.936823732309998e+31 W =  [[1.05139060e+13]\n",
      " [3.25042048e+13]\n",
      " [4.34781583e+13]] , b =  [1.53142805e+08]\n",
      "step =  6000 error value =  4.936823732309998e+31 W =  [[1.05139060e+13]\n",
      " [3.25042048e+13]\n",
      " [4.34781583e+13]] , b =  [1.53142805e+08]\n",
      "step =  6400 error value =  4.936823732309998e+31 W =  [[1.05139060e+13]\n",
      " [3.25042048e+13]\n",
      " [4.34781583e+13]] , b =  [1.53142805e+08]\n",
      "step =  6800 error value =  4.936823732309998e+31 W =  [[1.05139060e+13]\n",
      " [3.25042048e+13]\n",
      " [4.34781583e+13]] , b =  [1.53142805e+08]\n",
      "step =  7200 error value =  4.936823732309998e+31 W =  [[1.05139060e+13]\n",
      " [3.25042048e+13]\n",
      " [4.34781583e+13]] , b =  [1.53142805e+08]\n",
      "step =  7600 error value =  4.936823732309998e+31 W =  [[1.05139060e+13]\n",
      " [3.25042048e+13]\n",
      " [4.34781583e+13]] , b =  [1.53142805e+08]\n",
      "step =  8000 error value =  4.936823732309998e+31 W =  [[1.05139060e+13]\n",
      " [3.25042048e+13]\n",
      " [4.34781583e+13]] , b =  [1.53142805e+08]\n",
      "step =  8400 error value =  4.936823732309998e+31 W =  [[1.05139060e+13]\n",
      " [3.25042048e+13]\n",
      " [4.34781583e+13]] , b =  [1.53142805e+08]\n",
      "step =  8800 error value =  4.936823732309998e+31 W =  [[1.05139060e+13]\n",
      " [3.25042048e+13]\n",
      " [4.34781583e+13]] , b =  [1.53142805e+08]\n",
      "step =  9200 error value =  4.936823732309998e+31 W =  [[1.05139060e+13]\n",
      " [3.25042048e+13]\n",
      " [4.34781583e+13]] , b =  [1.53142805e+08]\n",
      "step =  9600 error value =  4.936823732309998e+31 W =  [[1.05139060e+13]\n",
      " [3.25042048e+13]\n",
      " [4.34781583e+13]] , b =  [1.53142805e+08]\n",
      "step =  10000 error value =  4.936823732309998e+31 W =  [[1.05139060e+13]\n",
      " [3.25042048e+13]\n",
      " [4.34781583e+13]] , b =  [1.53142805e+08]\n",
      "\n",
      "Elapsed Time =>  0:00:01.566000\n"
     ]
    }
   ],
   "source": [
    "# reset 하지 않은채 하이퍼파라미터 변경\n",
    "\n",
    "obj2 = LinearRegressionTest(x_data, t_data, 1e-3, 10001)\n",
    "\n",
    "obj2.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7.75853365e+15])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = np.array([100, 98, 81])\n",
    "\n",
    "obj2.predict(test_data) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### learning_rate = 1e-6,  반복횟수 10,000번 수행하는 obj3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearRegressionTest Object is created\n",
      "Initial error value =  1040.3314593348994 Initial W =  [[0.04398537]\n",
      " [0.66704495]\n",
      " [0.89780082]] \n",
      " , b =  [0.67578578]\n",
      "step =  0 error value =  961.0101833072055 W =  [[0.04912337]\n",
      " [0.67219683]\n",
      " [0.90308874]] , b =  [0.67584672]\n",
      "step =  400 error value =  8.159007563173821 W =  [[0.17669052]\n",
      " [0.79474923]\n",
      " [1.03479898]] , b =  [0.67727695]\n",
      "step =  800 error value =  8.101415167846344 W =  [[0.17839696]\n",
      " [0.79082662]\n",
      " [1.03697463]] , b =  [0.67720883]\n",
      "step =  1200 error value =  8.045634905043217 W =  [[0.18008776]\n",
      " [0.78696546]\n",
      " [1.03910538]] , b =  [0.67714047]\n",
      "step =  1600 error value =  7.991607410988173 W =  [[0.18176307]\n",
      " [0.78316478]\n",
      " [1.0411921 ]] , b =  [0.67707187]\n",
      "step =  2000 error value =  7.939275317818733 W =  [[0.18342303]\n",
      " [0.77942358]\n",
      " [1.04323562]] , b =  [0.67700304]\n",
      "step =  2400 error value =  7.88858318538691 W =  [[0.18506775]\n",
      " [0.77574087]\n",
      " [1.04523677]] , b =  [0.67693398]\n",
      "step =  2800 error value =  7.839477435424962 W =  [[0.18669738]\n",
      " [0.77211572]\n",
      " [1.04719636]] , b =  [0.6768647]\n",
      "step =  3200 error value =  7.791906287981679 W =  [[0.18831204]\n",
      " [0.76854717]\n",
      " [1.0491152 ]] , b =  [0.6767952]\n",
      "step =  3600 error value =  7.745819700049305 W =  [[0.18991186]\n",
      " [0.7650343 ]\n",
      " [1.05099404]] , b =  [0.67672548]\n",
      "step =  4000 error value =  7.701169306306728 W =  [[0.19149696]\n",
      " [0.7615762 ]\n",
      " [1.05283367]] , b =  [0.67665555]\n",
      "step =  4400 error value =  7.657908361903825 W =  [[0.19306746]\n",
      " [0.75817197]\n",
      " [1.05463484]] , b =  [0.67658542]\n",
      "step =  4800 error value =  7.61599168721783 W =  [[0.1946235 ]\n",
      " [0.75482075]\n",
      " [1.05639828]] , b =  [0.67651508]\n",
      "step =  5200 error value =  7.575375614512158 W =  [[0.1961652 ]\n",
      " [0.75152166]\n",
      " [1.05812472]] , b =  [0.67644455]\n",
      "step =  5600 error value =  7.536017936432428 W =  [[0.19769267]\n",
      " [0.74827385]\n",
      " [1.05981486]] , b =  [0.67637383]\n",
      "step =  6000 error value =  7.497877856275933 W =  [[0.19920605]\n",
      " [0.74507648]\n",
      " [1.06146942]] , b =  [0.67630291]\n",
      "step =  6400 error value =  7.460915939972806 W =  [[0.20070544]\n",
      " [0.74192875]\n",
      " [1.06308906]] , b =  [0.67623182]\n",
      "step =  6800 error value =  7.425094069719957 W =  [[0.20219098]\n",
      " [0.73882983]\n",
      " [1.06467447]] , b =  [0.67616054]\n",
      "step =  7200 error value =  7.390375399210081 W =  [[0.20366278]\n",
      " [0.73577894]\n",
      " [1.06622631]] , b =  [0.67608909]\n",
      "step =  7600 error value =  7.356724310401239 W =  [[0.20512096]\n",
      " [0.73277529]\n",
      " [1.06774521]] , b =  [0.67601746]\n",
      "step =  8000 error value =  7.324106371772891 W =  [[0.20656564]\n",
      " [0.72981811]\n",
      " [1.06923183]] , b =  [0.67594567]\n",
      "step =  8400 error value =  7.292488298017283 W =  [[0.20799693]\n",
      " [0.72690666]\n",
      " [1.07068678]] , b =  [0.67587371]\n",
      "step =  8800 error value =  7.26183791111648 W =  [[0.20941495]\n",
      " [0.72404018]\n",
      " [1.07211067]] , b =  [0.67580159]\n",
      "step =  9200 error value =  7.232124102756944 W =  [[0.21081982]\n",
      " [0.72121796]\n",
      " [1.07350411]] , b =  [0.67572931]\n",
      "step =  9600 error value =  7.203316798035765 W =  [[0.21221164]\n",
      " [0.71843926]\n",
      " [1.07486769]] , b =  [0.67565687]\n",
      "step =  10000 error value =  7.1753869204131275 W =  [[0.21359054]\n",
      " [0.7157034 ]\n",
      " [1.07620198]] , b =  [0.67558429]\n",
      "\n",
      "Elapsed Time =>  0:00:01.553000\n"
     ]
    }
   ],
   "source": [
    "# obj3 생성\n",
    "\n",
    "obj3 = LinearRegressionTest(x_data, t_data, 1e-6, 10001)\n",
    "\n",
    "obj3.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([179.34593118])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = np.array([100, 98, 81])\n",
    "\n",
    "obj3.predict(test_data) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### learning_rate = 1e-5,  반복횟수 8,000번 수행하는 obj4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearRegressionTest Object is created\n",
      "Initial error value =  3859.522758658984 Initial W =  [[0.04839035]\n",
      " [0.34522903]\n",
      " [0.84206034]] \n",
      " , b =  [0.81446935]\n",
      "step =  0 error value =  1431.035247642392 W =  [[0.14759425]\n",
      " [0.44493969]\n",
      " [0.94413579]] , b =  [0.8152147]\n",
      "step =  400 error value =  6.354400277539583 W =  [[0.30649641]\n",
      " [0.590055  ]\n",
      " [1.10700923]] , b =  [0.8155944]\n",
      "step =  800 error value =  6.328701709734579 W =  [[0.31106324]\n",
      " [0.58181022]\n",
      " [1.11063721]] , b =  [0.81481031]\n",
      "step =  1200 error value =  6.309590210802766 W =  [[0.31521868]\n",
      " [0.57473279]\n",
      " [1.11352431]] , b =  [0.81402272]\n",
      "step =  1600 error value =  6.295285831333713 W =  [[0.31899813]\n",
      " [0.56864927]\n",
      " [1.1158056 ]] , b =  [0.81323241]\n",
      "step =  2000 error value =  6.284506663049473 W =  [[0.3224342 ]\n",
      " [0.56341292]\n",
      " [1.11759277]] , b =  [0.81244001]\n",
      "step =  2400 error value =  6.276326059492162 W =  [[0.32555693]\n",
      " [0.55889943]\n",
      " [1.1189781 ]] , b =  [0.81164602]\n",
      "step =  2800 error value =  6.270071452623943 W =  [[0.32839392]\n",
      " [0.55500345]\n",
      " [1.12003769]] , b =  [0.81085086]\n",
      "step =  3200 error value =  6.2652525216463895 W =  [[0.33097052]\n",
      " [0.55163563]\n",
      " [1.12083424]] , b =  [0.81005486]\n",
      "step =  3600 error value =  6.261510097631969 W =  [[0.33330995]\n",
      " [0.54872008]\n",
      " [1.12141934]] , b =  [0.80925829]\n",
      "step =  4000 error value =  6.258579735925759 W =  [[0.33543348]\n",
      " [0.54619232]\n",
      " [1.1218353 ]] , b =  [0.80846135]\n",
      "step =  4400 error value =  6.25626567943592 W =  [[0.33736057]\n",
      " [0.54399751]\n",
      " [1.12211682]] , b =  [0.80766423]\n",
      "step =  4800 error value =  6.2544221955164225 W =  [[0.33910901]\n",
      " [0.54208893]\n",
      " [1.12229227]] , b =  [0.80686704]\n",
      "step =  5200 error value =  6.252940155441781 W =  [[0.34069501]\n",
      " [0.54042678]\n",
      " [1.12238476]] , b =  [0.8060699]\n",
      "step =  5600 error value =  6.251737349539703 W =  [[0.34213342]\n",
      " [0.53897707]\n",
      " [1.1224131 ]] , b =  [0.80527288]\n",
      "step =  6000 error value =  6.250751470812884 W =  [[0.34343772]\n",
      " [0.53771078]\n",
      " [1.12239252]] , b =  [0.80447605]\n",
      "step =  6400 error value =  6.249935010067622 W =  [[0.34462025]\n",
      " [0.53660308]\n",
      " [1.12233532]] , b =  [0.80367944]\n",
      "step =  6800 error value =  6.249251524578759 W =  [[0.34569219]\n",
      " [0.5356327 ]\n",
      " [1.12225139]] , b =  [0.80288309]\n",
      "step =  7200 error value =  6.248672897152522 W =  [[0.34666378]\n",
      " [0.53478141]\n",
      " [1.12214862]] , b =  [0.80208703]\n",
      "step =  7600 error value =  6.248177312057129 W =  [[0.34754428]\n",
      " [0.53403355]\n",
      " [1.12203328]] , b =  [0.80129126]\n",
      "step =  8000 error value =  6.247747752011528 W =  [[0.34834216]\n",
      " [0.53337567]\n",
      " [1.12191034]] , b =  [0.80049579]\n",
      "\n",
      "Elapsed Time =>  0:00:01.270000\n"
     ]
    }
   ],
   "source": [
    "# obj4 생성\n",
    "\n",
    "obj4 = LinearRegressionTest(x_data, t_data, 1e-5, 8001)\n",
    "\n",
    "obj4.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([178.78026376])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = np.array([100, 98, 81])\n",
    "\n",
    "obj4.predict(test_data) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### learning_rate = 1e-5,  반복횟수 6,000번 수행하는 obj5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearRegressionTest Object is created\n",
      "Initial error value =  64.61266127043513 Initial W =  [[0.84898122]\n",
      " [0.50863367]\n",
      " [0.57322525]] \n",
      " , b =  [0.82044779]\n",
      "step =  0 error value =  33.04936214252628 W =  [[0.86015484]\n",
      " [0.51994674]\n",
      " [0.58504486]] , b =  [0.82053256]\n",
      "step =  400 error value =  12.616105997249877 W =  [[0.82694436]\n",
      " [0.51787769]\n",
      " [0.67168057]] , b =  [0.820452]\n",
      "step =  800 error value =  11.169175076072834 W =  [[0.7812032 ]\n",
      " [0.50310799]\n",
      " [0.73057111]] , b =  [0.820163]\n",
      "step =  1200 error value =  10.0722487575273 W =  [[0.73996686]\n",
      " [0.49230754]\n",
      " [0.78120561]] , b =  [0.81980837]\n",
      "step =  1600 error value =  9.235610684815152 W =  [[0.70278176]\n",
      " [0.48468102]\n",
      " [0.82480195]] , b =  [0.81939724]\n",
      "step =  2000 error value =  8.593671900962798 W =  [[0.66924156]\n",
      " [0.47957681]\n",
      " [0.86239173]] , b =  [0.81893738]\n",
      "step =  2400 error value =  8.098243093691172 W =  [[0.63898196]\n",
      " [0.47646228]\n",
      " [0.89484941]] , b =  [0.81843543]\n",
      "step =  2800 error value =  7.713731059799472 W =  [[0.61167621]\n",
      " [0.47490312]\n",
      " [0.92291688]] , b =  [0.81789708]\n",
      "step =  3200 error value =  7.413699658243633 W =  [[0.58703101]\n",
      " [0.47454627]\n",
      " [0.94722413]] , b =  [0.8173272]\n",
      "step =  3600 error value =  7.178400118344686 W =  [[0.564783  ]\n",
      " [0.47510568]\n",
      " [0.9683066 ]] , b =  [0.81672999]\n",
      "step =  4000 error value =  6.992991432895821 W =  [[0.54469553]\n",
      " [0.47635048]\n",
      " [0.98661986]] , b =  [0.81610902]\n",
      "step =  4400 error value =  6.846253185635485 W =  [[0.52655585]\n",
      " [0.47809517]\n",
      " [1.00255188]] , b =  [0.81546741]\n",
      "step =  4800 error value =  6.729650709264072 W =  [[0.51017266]\n",
      " [0.4801915 ]\n",
      " [1.01643344]] , b =  [0.8148078]\n",
      "step =  5200 error value =  6.636653084576202 W =  [[0.49537381]\n",
      " [0.48252172]\n",
      " [1.02854687]] , b =  [0.8141325]\n",
      "step =  5600 error value =  6.562233188516078 W =  [[0.48200437]\n",
      " [0.48499302]\n",
      " [1.03913341]] , b =  [0.8134435]\n",
      "step =  6000 error value =  6.502499302640566 W =  [[0.46992483]\n",
      " [0.48753292]\n",
      " [1.04839946]] , b =  [0.8127425]\n",
      "\n",
      "Elapsed Time =>  0:00:00.939000\n"
     ]
    }
   ],
   "source": [
    "# obj5 생성\n",
    "\n",
    "obj5 = LinearRegressionTest(x_data, t_data, 1e-5, 6001)\n",
    "\n",
    "obj5.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([180.50380792])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = np.array([100, 98, 81])\n",
    "\n",
    "obj5.predict(test_data) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### learning_rate = 1e-5,  반복횟수 20,000번 수행하는 obj6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearRegressionTest Object is created\n",
      "Initial error value =  4434.867268387614 Initial W =  [[0.15332245]\n",
      " [0.42919179]\n",
      " [0.6100074 ]] \n",
      " , b =  [0.29707291]\n",
      "step =  0 error value =  1644.83857623551 W =  [[0.25962112]\n",
      " [0.53601257]\n",
      " [0.71950358]] , b =  [0.29787281]\n",
      "step =  400 error value =  7.5233807223007725 W =  [[0.41721749]\n",
      " [0.6717548 ]\n",
      " [0.92579074]] , b =  [0.29865608]\n",
      "step =  800 error value =  7.118585325908246 W =  [[0.41070373]\n",
      " [0.64674498]\n",
      " [0.956567  ]] , b =  [0.2981572]\n",
      "step =  1200 error value =  6.833876063339966 W =  [[0.40492193]\n",
      " [0.6259849 ]\n",
      " [0.98247943]] , b =  [0.29762508]\n",
      "step =  1600 error value =  6.633497312217189 W =  [[0.39978413]\n",
      " [0.60876554]\n",
      " [1.00430627]] , b =  [0.29706499]\n",
      "step =  2000 error value =  6.4923615725525154 W =  [[0.39521378]\n",
      " [0.594495  ]\n",
      " [1.02270034]] , b =  [0.29648133]\n",
      "step =  2400 error value =  6.392862516468547 W =  [[0.39114405]\n",
      " [0.58267922]\n",
      " [1.03820928]] , b =  [0.29587782]\n",
      "step =  2800 error value =  6.322640818809015 W =  [[0.3875166 ]\n",
      " [0.57290595]\n",
      " [1.05129264]] , b =  [0.29525757]\n",
      "step =  3200 error value =  6.273017790645035 W =  [[0.38428037]\n",
      " [0.56483127]\n",
      " [1.06233609]] , b =  [0.29462321]\n",
      "step =  3600 error value =  6.237897098836523 W =  [[0.38139061]\n",
      " [0.55816836]\n",
      " [1.07166336]] , b =  [0.29397695]\n",
      "step =  4000 error value =  6.212994602767045 W =  [[0.37880808]\n",
      " [0.55267807]\n",
      " [1.07954627]] , b =  [0.29332065]\n",
      "step =  4400 error value =  6.195298209390874 W =  [[0.37649829]\n",
      " [0.54816111]\n",
      " [1.08621308]] , b =  [0.29265587]\n",
      "step =  4800 error value =  6.18268898993517 W =  [[0.37443086]\n",
      " [0.54445143]\n",
      " [1.09185554]] , b =  [0.29198393]\n",
      "step =  5200 error value =  6.173675364923936 W =  [[0.37257907]\n",
      " [0.54141075]\n",
      " [1.09663477]] , b =  [0.29130595]\n",
      "step =  5600 error value =  6.167206575622344 W =  [[0.3709193 ]\n",
      " [0.53892395]\n",
      " [1.10068618]] , b =  [0.29062285]\n",
      "step =  6000 error value =  6.162541760330564 W =  [[0.3694307 ]\n",
      " [0.53689525]\n",
      " [1.10412362]] , b =  [0.28993543]\n",
      "step =  6400 error value =  6.159158033129882 W =  [[0.36809483]\n",
      " [0.53524503]\n",
      " [1.10704284]] , b =  [0.28924436]\n",
      "step =  6800 error value =  6.15668592459565 W =  [[0.36689533]\n",
      " [0.53390708]\n",
      " [1.1095244 ]] , b =  [0.28855021]\n",
      "step =  7200 error value =  6.154864022085047 W =  [[0.36581773]\n",
      " [0.53282642]\n",
      " [1.11163609]] , b =  [0.28785344]\n",
      "step =  7600 error value =  6.153507085352239 W =  [[0.36484916]\n",
      " [0.53195744]\n",
      " [1.113435  ]] , b =  [0.28715446]\n",
      "step =  8000 error value =  6.152483622524709 W =  [[0.36397818]\n",
      " [0.53126228]\n",
      " [1.11496922]] , b =  [0.28645362]\n",
      "step =  8400 error value =  6.151700109875298 W =  [[0.36319462]\n",
      " [0.53070959]\n",
      " [1.11627928]] , b =  [0.2857512]\n",
      "step =  8800 error value =  6.15108987913679 W =  [[0.36248942]\n",
      " [0.53027341]\n",
      " [1.11739935]] , b =  [0.28504745]\n",
      "step =  9200 error value =  6.150605285390131 W =  [[0.3618545 ]\n",
      " [0.52993227]\n",
      " [1.11835825]] , b =  [0.28434258]\n",
      "step =  9600 error value =  6.1502121818692785 W =  [[0.36128266]\n",
      " [0.52966844]\n",
      " [1.11918033]] , b =  [0.28363676]\n",
      "step =  10000 error value =  6.1498860179563755 W =  [[0.36076745]\n",
      " [0.52946728]\n",
      " [1.11988612]] , b =  [0.28293014]\n",
      "step =  10400 error value =  6.149609080064682 W =  [[0.36030313]\n",
      " [0.52931675]\n",
      " [1.12049299]] , b =  [0.28222285]\n",
      "step =  10800 error value =  6.149368537862958 W =  [[0.35988455]\n",
      " [0.52920692]\n",
      " [1.12101565]] , b =  [0.28151501]\n",
      "step =  11200 error value =  6.149155058506207 W =  [[0.35950709]\n",
      " [0.52912966]\n",
      " [1.12146651]] , b =  [0.28080669]\n",
      "step =  11600 error value =  6.148961821902153 W =  [[0.35916665]\n",
      " [0.52907829]\n",
      " [1.1218561 ]] , b =  [0.28009799]\n",
      "step =  12000 error value =  6.148783819467736 W =  [[0.3588595 ]\n",
      " [0.52904737]\n",
      " [1.12219336]] , b =  [0.27938897]\n",
      "step =  12400 error value =  6.148617353562799 W =  [[0.35858235]\n",
      " [0.52903244]\n",
      " [1.12248585]] , b =  [0.27867968]\n",
      "step =  12800 error value =  6.148459679204762 W =  [[0.3583322 ]\n",
      " [0.52902988]\n",
      " [1.12273999]] , b =  [0.27797018]\n",
      "step =  13200 error value =  6.148308746845035 W =  [[0.35810638]\n",
      " [0.52903677]\n",
      " [1.12296126]] , b =  [0.27726052]\n",
      "step =  13600 error value =  6.148163017077024 W =  [[0.3579025 ]\n",
      " [0.52905074]\n",
      " [1.1231543 ]] , b =  [0.27655071]\n",
      "step =  14000 error value =  6.148021326662657 W =  [[0.35771839]\n",
      " [0.52906989]\n",
      " [1.12332307]] , b =  [0.27584081]\n",
      "step =  14400 error value =  6.147882791267263 W =  [[0.35755211]\n",
      " [0.52909269]\n",
      " [1.12347094]] , b =  [0.27513084]\n",
      "step =  14800 error value =  6.147746734530057 W =  [[0.35740191]\n",
      " [0.52911794]\n",
      " [1.12360079]] , b =  [0.27442081]\n",
      "step =  15200 error value =  6.147612636091059 W =  [[0.35726622]\n",
      " [0.52914468]\n",
      " [1.12371509]] , b =  [0.27371075]\n",
      "step =  15600 error value =  6.14748009331212 W =  [[0.35714362]\n",
      " [0.52917216]\n",
      " [1.12381593]] , b =  [0.27300067]\n",
      "step =  16000 error value =  6.147348792930873 W =  [[0.35703283]\n",
      " [0.52919982]\n",
      " [1.12390512]] , b =  [0.2722906]\n",
      "step =  16400 error value =  6.147218489950851 W =  [[0.35693272]\n",
      " [0.5292272 ]\n",
      " [1.12398421]] , b =  [0.27158055]\n",
      "step =  16800 error value =  6.147088991827724 W =  [[0.35684223]\n",
      " [0.52925399]\n",
      " [1.12405451]] , b =  [0.27087052]\n",
      "step =  17200 error value =  6.146960146552037 W =  [[0.35676045]\n",
      " [0.52927995]\n",
      " [1.12411719]] , b =  [0.27016052]\n",
      "step =  17600 error value =  6.146831833613423 W =  [[0.35668652]\n",
      " [0.5293049 ]\n",
      " [1.12417321]] , b =  [0.26945057]\n",
      "step =  18000 error value =  6.146703957108534 W =  [[0.35661968]\n",
      " [0.52932873]\n",
      " [1.12422342]] , b =  [0.26874067]\n",
      "step =  18400 error value =  6.146576440452005 W =  [[0.35655925]\n",
      " [0.52935137]\n",
      " [1.12426857]] , b =  [0.26803084]\n",
      "step =  18800 error value =  6.146449222294674 W =  [[0.35650462]\n",
      " [0.5293728 ]\n",
      " [1.12430927]] , b =  [0.26732106]\n",
      "step =  19200 error value =  6.1463222533552315 W =  [[0.35645522]\n",
      " [0.52939301]\n",
      " [1.12434608]] , b =  [0.26661136]\n",
      "step =  19600 error value =  6.146195493947988 W =  [[0.35641055]\n",
      " [0.52941201]\n",
      " [1.12437947]] , b =  [0.26590173]\n",
      "step =  20000 error value =  6.146068912044123 W =  [[0.35637015]\n",
      " [0.52942982]\n",
      " [1.12440987]] , b =  [0.26519218]\n",
      "\n",
      "Elapsed Time =>  0:00:03.052000\n"
     ]
    }
   ],
   "source": [
    "# obj6 생성\n",
    "\n",
    "obj6 = LinearRegressionTest(x_data, t_data, 1e-5, 20001)\n",
    "\n",
    "obj6.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([178.86352902])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = np.array([100, 98, 81])\n",
    "\n",
    "obj6.predict(test_data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
