{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# x_data = (예습시간, 복습시간)\n",
    "# t_data = 1 (Pass), 0 (Fail)\n",
    "\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "x_data = [ [2, 4], [4, 11], [6, 6], [8, 5], [10, 7], [12, 16], [14, 8], [16, 3], [18, 7] ]\n",
    "t_data = [0, 0, 0, 0, 1, 1, 1, 1, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W =  [[0.30942549]\n",
      " [0.76755064]] , W.shape =  (2, 1) , b =  [0.69831944] , b.shape =  (1,)\n"
     ]
    }
   ],
   "source": [
    "W = np.random.rand(2, 1)  # 2X1 행렬\n",
    "b = np.random.rand(1)  \n",
    "print(\"W = \", W, \", W.shape = \", W.shape, \", b = \", b, \", b.shape = \", b.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# classification 이므로 출력함수로 sigmoid 정의\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1+np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 최종출력은 y = sigmoid(Wx+b) 이며, 손실함수는 cross-entropy 로 나타냄\n",
    "\n",
    "def loss_func(x, t):\n",
    "    \n",
    "    delta = 1e-7    # log 무한대 발산 방지\n",
    "    \n",
    "    z = np.dot(x, W) + b\n",
    "    y = sigmoid(z)\n",
    "    \n",
    "    # cross-entropy \n",
    "    return  -np.sum( t*np.log(y + delta) + (1-t)*np.log((1 - y)+delta ) )  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def numerical_derivative(f, x):\n",
    "    delta_x = 1e-4 # 0.0001\n",
    "    grad = np.zeros_like(x)\n",
    "    \n",
    "    it = np.nditer(x, flags=['multi_index'], op_flags=['readwrite'])\n",
    "    \n",
    "    while not it.finished:\n",
    "        idx = it.multi_index        \n",
    "        tmp_val = x[idx]\n",
    "        x[idx] = float(tmp_val) + delta_x\n",
    "        fx1 = f(x) # f(x+delta_x)\n",
    "        \n",
    "        x[idx] = tmp_val - delta_x \n",
    "        fx2 = f(x) # f(x-delta_x)\n",
    "        grad[idx] = (fx1 - fx2) / (2*delta_x)\n",
    "        \n",
    "        x[idx] = tmp_val \n",
    "        it.iternext()   \n",
    "        \n",
    "    return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def error_val(x, t):\n",
    "    delta = 1e-7    # log 무한대 발산 방지\n",
    "    \n",
    "    z = np.dot(x, W) + b\n",
    "    y = sigmoid(z)\n",
    "    \n",
    "    # cross-entropy \n",
    "    return  -np.sum( t*np.log(y + delta) + (1-t)*np.log((1 - y)+delta ) )  \n",
    "\n",
    "def predict(x):\n",
    "    \n",
    "    z = np.dot(x, W) + b\n",
    "    y = sigmoid(z)\n",
    "    \n",
    "    if y > 0.5:\n",
    "        result = 1  # True\n",
    "    else:\n",
    "        result = 0  # False\n",
    "    \n",
    "    return y, result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial error value =  28.9491877693172 Initial W =  [[0.30942549]\n",
      " [0.76755064]] \n",
      " , b =  [0.69831944]\n",
      "step =  0 error value =  18.170546229081623 W =  [[0.11000636]\n",
      " [0.50852295]] , b =  [0.6593761]\n",
      "step =  1000 error value =  1.4194953335343519 W =  [[ 0.58019158]\n",
      " [-0.00780487]] , b =  [-4.83266314]\n",
      "step =  2000 error value =  0.9792918335926044 W =  [[0.75156162]\n",
      " [0.05381923]] , b =  [-6.90389791]\n",
      "step =  3000 error value =  0.7927354032080012 W =  [[0.86968479]\n",
      " [0.09382544]] , b =  [-8.26225489]\n",
      "step =  4000 error value =  0.6822848525611799 W =  [[0.96060194]\n",
      " [0.12785079]] , b =  [-9.30929192]\n",
      "step =  5000 error value =  0.6059418945994259 W =  [[1.03455161]\n",
      " [0.16001095]] , b =  [-10.180316]\n",
      "step =  6000 error value =  0.5483656272445364 W =  [[1.09681622]\n",
      " [0.19157679]] , b =  [-10.93692933]\n",
      "step =  7000 error value =  0.5025076078754189 W =  [[1.15061462]\n",
      " [0.22278354]] , b =  [-11.61222879]\n",
      "step =  8000 error value =  0.46462813730739655 W =  [[1.19811133]\n",
      " [0.25346115]] , b =  [-12.22597939]\n",
      "step =  9000 error value =  0.43253331859635963 W =  [[1.24082782]\n",
      " [0.28333396]] , b =  [-12.79090518]\n",
      "step =  10000 error value =  0.4048340848172093 W =  [[1.27984499]\n",
      " [0.31216478]] , b =  [-13.31569426]\n",
      "step =  11000 error value =  0.38059547632343427 W =  [[1.31593019]\n",
      " [0.33980412]] , b =  [-13.80657966]\n",
      "step =  12000 error value =  0.35915590590205476 W =  [[1.34962947]\n",
      " [0.36618798]] , b =  [-14.2682272]\n",
      "step =  13000 error value =  0.34002775040427474 W =  [[1.38133586]\n",
      " [0.39131621]] , b =  [-14.70425775]\n",
      "step =  14000 error value =  0.3228395946897434 W =  [[1.41133812]\n",
      " [0.41522929]] , b =  [-15.11756661]\n",
      "step =  15000 error value =  0.307300983295604 W =  [[1.43985405]\n",
      " [0.43799003]] , b =  [-15.5105259]\n",
      "step =  16000 error value =  0.2931799167950852 W =  [[1.4670527 ]\n",
      " [0.45967132]] , b =  [-15.88511749]\n",
      "step =  17000 error value =  0.2802878856350082 W =  [[1.49306903]\n",
      " [0.48034852]] , b =  [-16.24302356]\n",
      "step =  18000 error value =  0.2684695492209229 W =  [[1.51801354]\n",
      " [0.50009518]] , b =  [-16.58569014]\n",
      "step =  19000 error value =  0.25759539027915923 W =  [[1.54197871]\n",
      " [0.51898076]] , b =  [-16.9143734]\n",
      "step =  20000 error value =  0.24755634338302424 W =  [[1.56504339]\n",
      " [0.53706968]] , b =  [-17.23017403]\n",
      "step =  21000 error value =  0.23825977557756423 W =  [[1.5872758]\n",
      " [0.554421 ]] , b =  [-17.53406365]\n",
      "step =  22000 error value =  0.22962641934760492 W =  [[1.60873573]\n",
      " [0.57108856]] , b =  [-17.82690529]\n",
      "step =  23000 error value =  0.22158799296683013 W =  [[1.62947608]\n",
      " [0.58712124]] , b =  [-18.10946979]\n",
      "step =  24000 error value =  0.2140853276244116 W =  [[1.64954408]\n",
      " [0.60256341]] , b =  [-18.38244899]\n",
      "step =  25000 error value =  0.2070668751112399 W =  [[1.66898212]\n",
      " [0.61745531]] , b =  [-18.64646645]\n",
      "step =  26000 error value =  0.20048750587908823 W =  [[1.68782855]\n",
      " [0.63183346]] , b =  [-18.90208642]\n",
      "step =  27000 error value =  0.19430753176226373 W =  [[1.70611817]\n",
      " [0.64573106]] , b =  [-19.14982127]\n",
      "step =  28000 error value =  0.18849190465240157 W =  [[1.72388269]\n",
      " [0.65917834]] , b =  [-19.39013779]\n",
      "step =  29000 error value =  0.18300955447003786 W =  [[1.74115117]\n",
      " [0.67220287]] , b =  [-19.62346247]\n",
      "step =  30000 error value =  0.17783283847362127 W =  [[1.75795025]\n",
      " [0.68482984]] , b =  [-19.8501861]\n",
      "step =  31000 error value =  0.1729370803251802 W =  [[1.77430449]\n",
      " [0.69708231]] , b =  [-20.07066765]\n",
      "step =  32000 error value =  0.16830018207820696 W =  [[1.79023653]\n",
      " [0.70898147]] , b =  [-20.28523766]\n",
      "step =  33000 error value =  0.16390229582869498 W =  [[1.80576733]\n",
      " [0.72054675]] , b =  [-20.4942012]\n",
      "step =  34000 error value =  0.15972554449708595 W =  [[1.82091634]\n",
      " [0.73179609]] , b =  [-20.69784041]\n",
      "step =  35000 error value =  0.1557537833084107 W =  [[1.83570162]\n",
      " [0.74274602]] , b =  [-20.89641674]\n",
      "step =  36000 error value =  0.1519723951707162 W =  [[1.85013997]\n",
      " [0.75341184]] , b =  [-21.09017294]\n",
      "step =  37000 error value =  0.1483681144323888 W =  [[1.86424708]\n",
      " [0.76380773]] , b =  [-21.27933481]\n",
      "step =  38000 error value =  0.14492887451102446 W =  [[1.8780376 ]\n",
      " [0.77394682]] , b =  [-21.46411272]\n",
      "step =  39000 error value =  0.14164367569217146 W =  [[1.89152521]\n",
      " [0.78384134]] , b =  [-21.64470301]\n",
      "step =  40000 error value =  0.1385024700416593 W =  [[1.90472276]\n",
      " [0.79350266]] , b =  [-21.82128918]\n",
      "step =  41000 error value =  0.13549606089639898 W =  [[1.91764229]\n",
      " [0.8029414 ]] , b =  [-21.994043]\n",
      "step =  42000 error value =  0.1326160148201235 W =  [[1.93029511]\n",
      " [0.81216746]] , b =  [-22.16312549]\n",
      "step =  43000 error value =  0.12985458425515067 W =  [[1.94269186]\n",
      " [0.82119011]] , b =  [-22.32868779]\n",
      "step =  44000 error value =  0.1272046393831709 W =  [[1.95484257]\n",
      " [0.83001803]] , b =  [-22.49087196]\n",
      "step =  45000 error value =  0.12465960794031064 W =  [[1.96675669]\n",
      " [0.83865936]] , b =  [-22.64981165]\n",
      "step =  46000 error value =  0.12221342192358034 W =  [[1.97844313]\n",
      " [0.84712174]] , b =  [-22.80563282]\n",
      "step =  47000 error value =  0.1198604702857636 W =  [[1.98991033]\n",
      " [0.85541235]] , b =  [-22.95845426]\n",
      "step =  48000 error value =  0.11759555684810356 W =  [[2.00116627]\n",
      " [0.86353797]] , b =  [-23.10838814]\n",
      "step =  49000 error value =  0.11541386277209366 W =  [[2.01221848]\n",
      " [0.87150497]] , b =  [-23.25554049]\n",
      "step =  50000 error value =  0.11331091302465057 W =  [[2.02307413]\n",
      " [0.87931936]] , b =  [-23.40001165]\n",
      "step =  51000 error value =  0.11128254635003394 W =  [[2.03374   ]\n",
      " [0.88698683]] , b =  [-23.54189665]\n",
      "step =  52000 error value =  0.10932488832854402 W =  [[2.04422254]\n",
      " [0.89451275]] , b =  [-23.68128559]\n",
      "step =  53000 error value =  0.10743432715830945 W =  [[2.05452788]\n",
      " [0.9019022 ]] , b =  [-23.81826397]\n",
      "step =  54000 error value =  0.10560749184484644 W =  [[2.06466184]\n",
      " [0.90916   ]] , b =  [-23.952913]\n",
      "step =  55000 error value =  0.10384123252396733 W =  [[2.07462996]\n",
      " [0.91629072]] , b =  [-24.08530986]\n",
      "step =  56000 error value =  0.10213260267887544 W =  [[2.08443754]\n",
      " [0.9232987 ]] , b =  [-24.215528]\n",
      "step =  57000 error value =  0.10047884304238201 W =  [[2.09408959]\n",
      " [0.93018804]] , b =  [-24.34363734]\n",
      "step =  58000 error value =  0.09887736700100744 W =  [[2.10359094]\n",
      " [0.93696268]] , b =  [-24.46970452]\n",
      "step =  59000 error value =  0.09732574734041761 W =  [[2.11294617]\n",
      " [0.94362632]] , b =  [-24.59379308]\n",
      "step =  60000 error value =  0.09582170419064072 W =  [[2.12215965]\n",
      " [0.95018253]] , b =  [-24.71596365]\n",
      "step =  61000 error value =  0.09436309404646934 W =  [[2.13123559]\n",
      " [0.95663469]] , b =  [-24.83627414]\n",
      "step =  62000 error value =  0.09294789975306406 W =  [[2.14017798]\n",
      " [0.96298601]] , b =  [-24.95477988]\n",
      "step =  63000 error value =  0.09157422135925147 W =  [[2.14899066]\n",
      " [0.96923958]] , b =  [-25.07153381]\n",
      "step =  64000 error value =  0.09024026775228362 W =  [[2.15767731]\n",
      " [0.97539834]] , b =  [-25.18658654]\n",
      "step =  65000 error value =  0.08894434899734763 W =  [[2.16624145]\n",
      " [0.9814651 ]] , b =  [-25.29998656]\n",
      "step =  66000 error value =  0.08768486931363793 W =  [[2.17468646]\n",
      " [0.98744254]] , b =  [-25.41178033]\n",
      "step =  67000 error value =  0.08646032062625421 W =  [[2.18301557]\n",
      " [0.99333324]] , b =  [-25.52201238]\n",
      "step =  68000 error value =  0.08526927663961312 W =  [[2.1912319 ]\n",
      " [0.99913966]] , b =  [-25.6307254]\n",
      "step =  69000 error value =  0.08411038738406704 W =  [[2.19933844]\n",
      " [1.00486416]] , b =  [-25.73796041]\n",
      "step =  70000 error value =  0.08298237419202321 W =  [[2.20733805]\n",
      " [1.010509  ]] , b =  [-25.84375675]\n",
      "step =  71000 error value =  0.08188402506501367 W =  [[2.2152335 ]\n",
      " [1.01607636]] , b =  [-25.94815225]\n",
      "step =  72000 error value =  0.08081419039648341 W =  [[2.22302745]\n",
      " [1.02156831]] , b =  [-26.05118327]\n",
      "step =  73000 error value =  0.0797717790189861 W =  [[2.23072244]\n",
      " [1.02698687]] , b =  [-26.15288476]\n",
      "step =  74000 error value =  0.07875575454749735 W =  [[2.23832095]\n",
      " [1.03233394]] , b =  [-26.25329038]\n",
      "step =  75000 error value =  0.07776513199329388 W =  [[2.24582534]\n",
      " [1.03761139]] , b =  [-26.3524325]\n",
      "step =  76000 error value =  0.07679897462545418 W =  [[2.2532379 ]\n",
      " [1.04282098]] , b =  [-26.45034233]\n",
      "step =  77000 error value =  0.07585639105894122 W =  [[2.26056084]\n",
      " [1.04796443]] , b =  [-26.54704991]\n",
      "step =  78000 error value =  0.07493653255071077 W =  [[2.26779627]\n",
      " [1.05304339]] , b =  [-26.64258424]\n",
      "step =  79000 error value =  0.07403859048655033 W =  [[2.27494625]\n",
      " [1.05805944]] , b =  [-26.73697326]\n",
      "step =  80000 error value =  0.07316179404320444 W =  [[2.28201277]\n",
      " [1.06301411]] , b =  [-26.83024392]\n",
      "step =  81000 error value =  0.07230540801174876 W =  [[2.28899772]\n",
      " [1.06790887]] , b =  [-26.92242227]\n",
      "step =  82000 error value =  0.07146873076937946 W =  [[2.29590297]\n",
      " [1.07274516]] , b =  [-27.01353342]\n",
      "step =  83000 error value =  0.07065109238795934 W =  [[2.3027303 ]\n",
      " [1.07752434]] , b =  [-27.10360166]\n",
      "step =  84000 error value =  0.06985185286874132 W =  [[2.30948144]\n",
      " [1.08224773]] , b =  [-27.19265046]\n",
      "step =  85000 error value =  0.06907040049345718 W =  [[2.31615805]\n",
      " [1.08691662]] , b =  [-27.28070249]\n",
      "step =  86000 error value =  0.06830615028310608 W =  [[2.32276175]\n",
      " [1.09153223]] , b =  [-27.3677797]\n",
      "step =  87000 error value =  0.06755854255618615 W =  [[2.32929412]\n",
      " [1.09609577]] , b =  [-27.45390331]\n",
      "step =  88000 error value =  0.06682704157909962 W =  [[2.33575666]\n",
      " [1.1006084 ]] , b =  [-27.53909386]\n",
      "step =  89000 error value =  0.06611113430181842 W =  [[2.34215084]\n",
      " [1.10507122]] , b =  [-27.62337124]\n",
      "step =  90000 error value =  0.06541032917265123 W =  [[2.34847808]\n",
      " [1.10948531]] , b =  [-27.70675471]\n",
      "step =  91000 error value =  0.06472415502651274 W =  [[2.35473977]\n",
      " [1.11385173]] , b =  [-27.78926293]\n",
      "step =  92000 error value =  0.06405216004123622 W =  [[2.36093723]\n",
      " [1.11817149]] , b =  [-27.87091399]\n",
      "step =  93000 error value =  0.06339391075728537 W =  [[2.36707178]\n",
      " [1.12244557]] , b =  [-27.95172541]\n",
      "step =  94000 error value =  0.06274899115637303 W =  [[2.37314465]\n",
      " [1.12667491]] , b =  [-28.0317142]\n",
      "step =  95000 error value =  0.062117001794892934 W =  [[2.37915708]\n",
      " [1.13086045]] , b =  [-28.11089685]\n",
      "step =  96000 error value =  0.061497558988429714 W =  [[2.38511025]\n",
      " [1.13500307]] , b =  [-28.18928937]\n",
      "step =  97000 error value =  0.06089029404385903 W =  [[2.3910053 ]\n",
      " [1.13910364]] , b =  [-28.26690729]\n",
      "step =  98000 error value =  0.06029485253579525 W =  [[2.39684336]\n",
      " [1.143163  ]] , b =  [-28.34376568]\n",
      "step =  99000 error value =  0.059710893624544494 W =  [[2.40262552]\n",
      " [1.14718196]] , b =  [-28.41987919]\n",
      "step =  100000 error value =  0.059138089412695556 W =  [[2.40835282]\n",
      " [1.15116132]] , b =  [-28.49526206]\n",
      "\n",
      "Elapsed Time =>  0:00:19.076000\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 1e-2  # 1e-2, 1e-3 은 손실함수 값 발산\n",
    "\n",
    "# x_data, t_data 는 list 이므로 numpy로 바꾸어주어야 함\n",
    "\n",
    "input_xdata = np.array(x_data)\n",
    "input_tdata = np.array(t_data).reshape(len(t_data), 1)\n",
    "\n",
    "f = lambda x : loss_func(input_xdata, input_tdata)\n",
    "\n",
    "print(\"Initial error value = \", error_val(input_xdata, input_tdata), \"Initial W = \", W, \"\\n\", \", b = \", b )\n",
    "\n",
    "start_time = datetime.now()\n",
    "\n",
    "for step in  range(100001):  \n",
    "    \n",
    "    W -= learning_rate * numerical_derivative(f, W)\n",
    "    \n",
    "    b -= learning_rate * numerical_derivative(f, b)\n",
    "    \n",
    "    if (step % 1000 == 0):\n",
    "        print(\"step = \", step, \"error value = \", error_val(input_xdata, input_tdata), \"W = \", W, \", b = \",b )\n",
    "        \n",
    "        \n",
    "end_time = datetime.now()\n",
    "\n",
    "print(\"\")\n",
    "print(\"Elapsed Time => \", end_time - start_time) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.15440505]), 0)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = np.array([3, 17]) # (예습, 복습) = (3, 17) => Fail (0)\n",
    "predict(test_data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.00071379]), 0)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = np.array([5, 8]) # (예습, 복습) = (5, 8) => Fail (0)\n",
    "\n",
    "predict(test_data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.99999641]), 1)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = np.array([7, 21]) # (예습, 복습) = (7, 21) => Pass (1)\n",
    "\n",
    "predict(test_data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.59988159]), 1)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = np.array([12, 0])  # (예습, 복습) = (12, 0) => Pass (1)\n",
    "\n",
    "predict(test_data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
