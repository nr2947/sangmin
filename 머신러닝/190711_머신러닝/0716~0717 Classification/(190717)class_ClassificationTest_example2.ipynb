{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "class SimpleClassificationTest:\n",
    "    \n",
    "    # constructor\n",
    "    def __init__(self, xdata, tdata, learning_rate, iteration_count):\n",
    "            \n",
    "        # 가중치 W 형상을 자동으로 구하기 위해 입력데이터가 vector 인지,\n",
    "        # 아니면 matrix 인지 체크 후, \n",
    "        # self.xdata 는 무조건 matrix 로 만들어 주면 코드 일관성이 있음\n",
    "        \n",
    "        if xdata.ndim == 1:    # vector\n",
    "            self.xdata = xdata.reshape(len(xdata), 1)\n",
    "            self.tdata = xdata.reshape(len(tdata), 1)\n",
    "            \n",
    "        elif xdata.ndim == 2:  # matrix\n",
    "            self.xdata = xdata\n",
    "            self.tdata = tdata\n",
    "        \n",
    "        self.learning_rate = learning_rate\n",
    "        self.iteration_count = iteration_count\n",
    "        \n",
    "        self.W = np.random.rand(self.xdata.shape[1], 1) \n",
    "        self.b = np.random.rand(1)\n",
    "        \n",
    "        print(\"SimpleClassificationTest Object is created\")\n",
    "        \n",
    "    \n",
    "    def sigmoid(self, z):\n",
    "        \n",
    "        return 1 / (1+np.exp(-z))\n",
    "        \n",
    "    # obtain current W and current b\n",
    "    def getW_b(self):\n",
    "        \n",
    "        return self.W, self.b\n",
    "    \n",
    "    \n",
    "    # loss function\n",
    "    def loss_func(self):\n",
    "        \n",
    "        delta = 1e-7    # log 무한대 발산 방지\n",
    "    \n",
    "        z = np.dot(self.xdata, self.W) + self.b\n",
    "        \n",
    "        y = self.sigmoid(z)\n",
    "    \n",
    "        # cross-entropy \n",
    "        return  -np.sum( self.tdata*np.log(y + delta) + (1-self.tdata)*np.log((1 - y)+delta ) ) \n",
    "        \n",
    "    \n",
    "    # display current error value\n",
    "    def error_val(self):\n",
    "        \n",
    "        delta = 1e-7    # log 무한대 발산 방지\n",
    "    \n",
    "        z = np.dot(self.xdata, self.W) + self.b\n",
    "        \n",
    "        y = self.sigmoid(z)\n",
    "    \n",
    "        # cross-entropy \n",
    "        return  -np.sum( self.tdata*np.log(y + delta) + (1-self.tdata)*np.log((1 - y)+delta ) ) \n",
    "    \n",
    "    \n",
    "    # predict method\n",
    "    # 학습을 마친 후, 임의의 데이터에 대해 미래 값 예측 함수\n",
    "    # 입력변수 x : numpy type\n",
    "    def predict(self, test_data):\n",
    "    \n",
    "        z = np.dot(test_data, self.W) + self.b\n",
    "        y = self.sigmoid(z)\n",
    "    \n",
    "        if y >= 0.5:\n",
    "            result = 1  # True\n",
    "        else:\n",
    "            result = 0  # False\n",
    "    \n",
    "        return y, result\n",
    "    \n",
    "    \n",
    "    # train method\n",
    "    def train(self):\n",
    "    \n",
    "        f = lambda x : self.loss_func()\n",
    "\n",
    "        print(\"Initial error value = \", self.error_val(), \"Initial W = \", self.W, \"\\n\", \", b = \", self.b )\n",
    "\n",
    "        start_time = datetime.now()\n",
    "        \n",
    "        for step in  range(self.iteration_count):  \n",
    "    \n",
    "            self.W -= self.learning_rate * numerical_derivative(f, self.W)\n",
    "    \n",
    "            self.b -= self.learning_rate * numerical_derivative(f, self.b)\n",
    "    \n",
    "            if (step % 1000 == 0):\n",
    "                print(\"step = \", step, \"error value = \", self.error_val(), \"W = \", self.W, \", b = \", self.b )\n",
    "                \n",
    "        end_time = datetime.now()\n",
    "        \n",
    "        print(\"\")\n",
    "        print(\"Elapsed Time => \", end_time - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def numerical_derivative(f, x):\n",
    "    delta_x = 1e-4 # 0.0001\n",
    "    grad = np.zeros_like(x)\n",
    "    \n",
    "    it = np.nditer(x, flags=['multi_index'], op_flags=['readwrite'])\n",
    "    \n",
    "    while not it.finished:\n",
    "        idx = it.multi_index        \n",
    "        tmp_val = x[idx]\n",
    "        x[idx] = float(tmp_val) + delta_x\n",
    "        fx1 = f(x) # f(x+delta_x)\n",
    "        \n",
    "        x[idx] = tmp_val - delta_x \n",
    "        fx2 = f(x) # f(x-delta_x)\n",
    "        grad[idx] = (fx1 - fx2) / (2*delta_x)\n",
    "        \n",
    "        x[idx] = tmp_val \n",
    "        it.iternext()   \n",
    "        \n",
    "    return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_data.shape =  (9, 2) , t_data.shape =  (9, 1)\n"
     ]
    }
   ],
   "source": [
    "# 입력데이터 / 정답데이터 세팅\n",
    "\n",
    "x_data = np.array( [ [2, 4], [4, 11], [6, 6], [8, 5], [10, 7], [12, 16], [14, 8], [16, 3], [18, 7] ] )\n",
    "t_data = np.array( [0, 0, 0, 0, 1, 1, 1, 1, 1] ).reshape(9, 1)\n",
    "\n",
    "print(\"x_data.shape = \", x_data.shape, \", t_data.shape = \", t_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# learning_rate = 1e-2,  반복횟수 100,000번 수행하는 obj1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SimpleClassificationTest Object is created\n",
      "Initial error value =  28.42746630889496 Initial W =  [[0.17313845]\n",
      " [0.90962442]] \n",
      " , b =  [0.32527418]\n",
      "step =  0 error value =  17.85463483027847 W =  [[-0.02561469]\n",
      " [ 0.65110709]] , b =  [0.28792046]\n",
      "step =  1000 error value =  1.3947924964215062 W =  [[ 0.5872846 ]\n",
      " [-0.00495549]] , b =  [-4.92278778]\n",
      "step =  2000 error value =  0.9709494147890586 W =  [[0.75606407]\n",
      " [0.05532485]] , b =  [-6.9561934]\n",
      "step =  3000 error value =  0.788264261731659 W =  [[0.87302562]\n",
      " [0.0950022 ]] , b =  [-8.30051579]\n",
      "step =  4000 error value =  0.6793564897454338 W =  [[0.96326362]\n",
      " [0.12892553]] , b =  [-9.34024685]\n",
      "step =  5000 error value =  0.6038045982431106 W =  [[1.03676126]\n",
      " [0.1610543 ]] , b =  [-10.2067569]\n",
      "step =  6000 error value =  0.5466994514118573 W =  [[1.09870408]\n",
      " [0.19260799]] , b =  [-10.96027191]\n",
      "step =  7000 error value =  0.5011514526357884 W =  [[1.15226534]\n",
      " [0.22380122]] , b =  [-11.63328557]\n",
      "step =  8000 error value =  0.4634910951891397 W =  [[1.19958368]\n",
      " [0.25445682]] , b =  [-12.24525802]\n",
      "step =  9000 error value =  0.4315595802087083 W =  [[1.24216347]\n",
      " [0.28429874]] , b =  [-12.80874388]\n",
      "step =  10000 error value =  0.40398702798783753 W =  [[1.28107356]\n",
      " [0.31309228]] , b =  [-13.33233056]\n",
      "step =  11000 error value =  0.37984972595365896 W =  [[1.3170727 ]\n",
      " [0.34069098]] , b =  [-13.82218814]\n",
      "step =  12000 error value =  0.35849307841343847 W =  [[1.35070094]\n",
      " [0.36703331]] , b =  [-14.28294124]\n",
      "step =  13000 error value =  0.33943403698086994 W =  [[1.38234723]\n",
      " [0.39212082]] , b =  [-14.71818265]\n",
      "step =  14000 error value =  0.32230431696451356 W =  [[1.41229751]\n",
      " [0.41599495]] , b =  [-15.13078773]\n",
      "step =  15000 error value =  0.30681568895794886 W =  [[1.44076769]\n",
      " [0.43871905]] , b =  [-15.52311396]\n",
      "step =  16000 error value =  0.2927377886044432 W =  [[1.46792551]\n",
      " [0.46036615]] , b =  [-15.89713211]\n",
      "step =  17000 error value =  0.2798833401723657 W =  [[1.49390499]\n",
      " [0.48101164]] , b =  [-16.2545157]\n",
      "step =  18000 error value =  0.26809795515794715 W =  [[1.51881594]\n",
      " [0.50072893]] , b =  [-16.59670388]\n",
      "step =  19000 error value =  0.25725286474925557 W =  [[1.54275035]\n",
      " [0.51958734]] , b =  [-16.92494719]\n",
      "step =  20000 error value =  0.24723960111690818 W =  [[1.56578665]\n",
      " [0.53765112]] , b =  [-17.24034173]\n",
      "step =  21000 error value =  0.2379660147565539 W =  [[1.58799277]\n",
      " [0.55497915]] , b =  [-17.54385523]\n",
      "step =  22000 error value =  0.22935323368019045 W =  [[1.60942826]\n",
      " [0.5716251 ]] , b =  [-17.83634746]\n",
      "step =  23000 error value =  0.22133330292129932 W =  [[1.6301458]\n",
      " [0.5876377]] , b =  [-18.11858648]\n",
      "step =  24000 error value =  0.2138473259319369 W =  [[1.65019245]\n",
      " [0.60306118]] , b =  [-18.3912617]\n",
      "step =  25000 error value =  0.20684398308159724 W =  [[1.66961047]\n",
      " [0.61793563]] , b =  [-18.65499462]\n",
      "step =  26000 error value =  0.20027833803147554 W =  [[1.68843807]\n",
      " [0.63229749]] , b =  [-18.91034767]\n",
      "step =  27000 error value =  0.19411086693309654 W =  [[1.70670995]\n",
      " [0.64617983]] , b =  [-19.15783163]\n",
      "step =  28000 error value =  0.18830666220660655 W =  [[1.72445773]\n",
      " [0.6596128 ]] , b =  [-19.39791188]\n",
      "step =  29000 error value =  0.1828347745739954 W =  [[1.74171038]\n",
      " [0.67262388]] , b =  [-19.63101368]\n",
      "step =  30000 error value =  0.17766766562975944 W =  [[1.75849447]\n",
      " [0.68523819]] , b =  [-19.8575267]\n",
      "step =  31000 error value =  0.17278074954750355 W =  [[1.77483448]\n",
      " [0.69747873]] , b =  [-20.07780894]\n",
      "step =  32000 error value =  0.16815200722157972 W =  [[1.79075301]\n",
      " [0.70936661]] , b =  [-20.29219005]\n",
      "step =  33000 error value =  0.16376165968662154 W =  [[1.80627097]\n",
      " [0.72092124]] , b =  [-20.50097432]\n",
      "step =  34000 error value =  0.1595918903603454 W =  [[1.82140776]\n",
      " [0.73216049]] , b =  [-20.70444315]\n",
      "step =  35000 error value =  0.15562660773753073 W =  [[1.83618137]\n",
      " [0.74310085]] , b =  [-20.90285737]\n",
      "step =  36000 error value =  0.15185124178227916 W =  [[1.8506086 ]\n",
      " [0.75375759]] , b =  [-21.09645914]\n",
      "step =  37000 error value =  0.1482525685362933 W =  [[1.86470509]\n",
      " [0.76414483]] , b =  [-21.28547372]\n",
      "step =  38000 error value =  0.14481855846525848 W =  [[1.87848543]\n",
      " [0.7742757 ]] , b =  [-21.47011102]\n",
      "step =  39000 error value =  0.14153824486512548 W =  [[1.89196332]\n",
      " [0.78416238]] , b =  [-21.65056691]\n",
      "step =  40000 error value =  0.13840160929126016 W =  [[1.90515155]\n",
      " [0.79381623]] , b =  [-21.82702451]\n",
      "step =  41000 error value =  0.13539948149008257 W =  [[1.91806214]\n",
      " [0.80324782]] , b =  [-21.99965522]\n",
      "step =  42000 error value =  0.1325234517327196 W =  [[1.93070638]\n",
      " [0.81246706]] , b =  [-22.16861971]\n",
      "step =  43000 error value =  0.12976579379146233 W =  [[1.94309489]\n",
      " [0.82148318]] , b =  [-22.33406883]\n",
      "step =  44000 error value =  0.12711939708073428 W =  [[1.95523769]\n",
      " [0.83030484]] , b =  [-22.49614432]\n",
      "step =  45000 error value =  0.1245777067143647 W =  [[1.96714418]\n",
      " [0.83894017]] , b =  [-22.6549796]\n",
      "step =  46000 error value =  0.12213467042246022 W =  [[1.9788233 ]\n",
      " [0.84739679]] , b =  [-22.81070038]\n",
      "step =  47000 error value =  0.11978469142919494 W =  [[1.99028343]\n",
      " [0.85568188]] , b =  [-22.9634252]\n",
      "step =  48000 error value =  0.1175225865252379 W =  [[2.00153255]\n",
      " [0.86380219]] , b =  [-23.11326605]\n",
      "step =  49000 error value =  0.11534354867920243 W =  [[2.0125782 ]\n",
      " [0.87176408]] , b =  [-23.26032876]\n",
      "step =  50000 error value =  0.1132431136253879 W =  [[2.0234275 ]\n",
      " [0.87957356]] , b =  [-23.40471347]\n",
      "step =  51000 error value =  0.11121712994348183 W =  [[2.03408725]\n",
      " [0.8872363 ]] , b =  [-23.54651507]\n",
      "step =  52000 error value =  0.10926173221214724 W =  [[2.04456388]\n",
      " [0.89475765]] , b =  [-23.68582348]\n",
      "step =  53000 error value =  0.1073733168747089 W =  [[2.05486349]\n",
      " [0.9021427 ]] , b =  [-23.82272407]\n",
      "step =  54000 error value =  0.10554852050295302 W =  [[2.06499192]\n",
      " [0.90939626]] , b =  [-23.9572979]\n",
      "step =  55000 error value =  0.10378420018587312 W =  [[2.07495468]\n",
      " [0.91652288]] , b =  [-24.08962204]\n",
      "step =  56000 error value =  0.10207741580530802 W =  [[2.08475707]\n",
      " [0.92352689]] , b =  [-24.21976981]\n",
      "step =  57000 error value =  0.10042541399025678 W =  [[2.0944041 ]\n",
      " [0.93041241]] , b =  [-24.34781102]\n",
      "step =  58000 error value =  0.09882561356752943 W =  [[2.10390058]\n",
      " [0.93718334]] , b =  [-24.47381221]\n",
      "step =  59000 error value =  0.0972755923486854 W =  [[2.11325108]\n",
      " [0.9438434 ]] , b =  [-24.59783681]\n",
      "step =  60000 error value =  0.09577307511251745 W =  [[2.12245998]\n",
      " [0.95039614]] , b =  [-24.71994536]\n",
      "step =  61000 error value =  0.0943159226588189 W =  [[2.13153147]\n",
      " [0.95684493]] , b =  [-24.8401957]\n",
      "step =  62000 error value =  0.09290212182397073 W =  [[2.14046954]\n",
      " [0.96319299]] , b =  [-24.95864306]\n",
      "step =  63000 error value =  0.09152977636123544 W =  [[2.14927802]\n",
      " [0.9694434 ]] , b =  [-25.07534031]\n",
      "step =  64000 error value =  0.09019709859983138 W =  [[2.15796059]\n",
      " [0.97559909]] , b =  [-25.19033798]\n",
      "step =  65000 error value =  0.08890240180638019 W =  [[2.16652077]\n",
      " [0.98166287]] , b =  [-25.30368451]\n",
      "step =  66000 error value =  0.08764409318088245 W =  [[2.17496191]\n",
      " [0.98763743]] , b =  [-25.41542628]\n",
      "step =  67000 error value =  0.08642066742651432 W =  [[2.18328727]\n",
      " [0.99352532]] , b =  [-25.52560775]\n",
      "step =  68000 error value =  0.08523070083935685 W =  [[2.19149995]\n",
      " [0.99932901]] , b =  [-25.63427158]\n",
      "step =  69000 error value =  0.08407284586974055 W =  [[2.19960293]\n",
      " [1.00505086]] , b =  [-25.7414587]\n",
      "step =  70000 error value =  0.08294582611190002 W =  [[2.20759908]\n",
      " [1.01069312]] , b =  [-25.84720843]\n",
      "step =  71000 error value =  0.08184843168316594 W =  [[2.21549115]\n",
      " [1.01625797]] , b =  [-25.95155854]\n",
      "step =  72000 error value =  0.08077951495794945 W =  [[2.22328181]\n",
      " [1.02174748]] , b =  [-26.05454533]\n",
      "step =  73000 error value =  0.07973798662506779 W =  [[2.23097359]\n",
      " [1.02716366]] , b =  [-26.15620372]\n",
      "step =  74000 error value =  0.07872281204037652 W =  [[2.23856897]\n",
      " [1.03250841]] , b =  [-26.25656732]\n",
      "step =  75000 error value =  0.0777330078491016 W =  [[2.24607031]\n",
      " [1.0377836 ]] , b =  [-26.35566847]\n",
      "step =  76000 error value =  0.0767676388550861 W =  [[2.25347989]\n",
      " [1.04299099]] , b =  [-26.45353833]\n",
      "step =  77000 error value =  0.07582581511606969 W =  [[2.26079992]\n",
      " [1.0481323 ]] , b =  [-26.55020692]\n",
      "step =  78000 error value =  0.07490668924625227 W =  [[2.26803251]\n",
      " [1.05320917]] , b =  [-26.64570318]\n",
      "step =  79000 error value =  0.07400945390914655 W =  [[2.27517972]\n",
      " [1.05822317]] , b =  [-26.74005503]\n",
      "step =  80000 error value =  0.0731333394852676 W =  [[2.28224352]\n",
      " [1.06317585]] , b =  [-26.8332894]\n",
      "step =  81000 error value =  0.07227761190049245 W =  [[2.28922583]\n",
      " [1.06806868]] , b =  [-26.92543229]\n",
      "step =  82000 error value =  0.07144157060261926 W =  [[2.2961285 ]\n",
      " [1.07290307]] , b =  [-27.0165088]\n",
      "step =  83000 error value =  0.07062454667413068 W =  [[2.30295329]\n",
      " [1.07768039]] , b =  [-27.10654319]\n",
      "step =  84000 error value =  0.06982590107092185 W =  [[2.30970195]\n",
      " [1.08240197]] , b =  [-27.19555888]\n",
      "step =  85000 error value =  0.06904502297710254 W =  [[2.31637615]\n",
      " [1.08706909]] , b =  [-27.28357855]\n",
      "step =  86000 error value =  0.06828132826713601 W =  [[2.32297748]\n",
      " [1.09168298]] , b =  [-27.37062409]\n",
      "step =  87000 error value =  0.06753425806723529 W =  [[2.32950753]\n",
      " [1.09624483]] , b =  [-27.45671673]\n",
      "step =  88000 error value =  0.06680327740862181 W =  [[2.3359678]\n",
      " [1.1007558]] , b =  [-27.54187696]\n",
      "step =  89000 error value =  0.0660878739659521 W =  [[2.34235976]\n",
      " [1.105217  ]] , b =  [-27.62612467]\n",
      "step =  90000 error value =  0.06538755687457477 W =  [[2.34868483]\n",
      " [1.10962951]] , b =  [-27.7094791]\n",
      "step =  91000 error value =  0.06470185562106669 W =  [[2.35494438]\n",
      " [1.11399438]] , b =  [-27.79195887]\n",
      "step =  92000 error value =  0.06403031900176229 W =  [[2.36113976]\n",
      " [1.11831263]] , b =  [-27.87358207]\n",
      "step =  93000 error value =  0.06337251414443745 W =  [[2.36727226]\n",
      " [1.12258522]] , b =  [-27.9543662]\n",
      "step =  94000 error value =  0.06272802558879727 W =  [[2.37334313]\n",
      " [1.12681311]] , b =  [-28.03432825]\n",
      "step =  95000 error value =  0.062096454421650085 W =  [[2.37935359]\n",
      " [1.13099722]] , b =  [-28.11348469]\n",
      "step =  96000 error value =  0.061477417463023036 W =  [[2.38530483]\n",
      " [1.13513844]] , b =  [-28.19185152]\n",
      "step =  97000 error value =  0.0608705464997782 W =  [[2.391198  ]\n",
      " [1.13923765]] , b =  [-28.26944424]\n",
      "step =  98000 error value =  0.06027548756346834 W =  [[2.3970342 ]\n",
      " [1.14329566]] , b =  [-28.34627793]\n",
      "step =  99000 error value =  0.05969190024961076 W =  [[2.40281454]\n",
      " [1.14731332]] , b =  [-28.42236722]\n",
      "step =  100000 error value =  0.05911945707546709 W =  [[2.40854006]\n",
      " [1.15129139]] , b =  [-28.49772632]\n",
      "\n",
      "Elapsed Time =>  0:00:21.120000\n"
     ]
    }
   ],
   "source": [
    "obj1 = SimpleClassificationTest(x_data, t_data, 1e-2, 100001)\n",
    "\n",
    "obj1.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.15444535] 0\n"
     ]
    }
   ],
   "source": [
    "test_data = np.array([3, 17]) # (예습, 복습) = (3, 17) => Fail (0)\n",
    "\n",
    "(real_val, logical_val) = obj1.predict(test_data)\n",
    "\n",
    "print(real_val, logical_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00071344] 0\n"
     ]
    }
   ],
   "source": [
    "test_data = np.array([5, 8]) # (예습, 복습) = (5, 8) => Fail (0)\n",
    "\n",
    "(real_val, logical_val) = obj1.predict(test_data)\n",
    "\n",
    "print(real_val, logical_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.99999642] 1\n"
     ]
    }
   ],
   "source": [
    "test_data = np.array([7, 21]) # (예습, 복습) = (7, 21) => Pass (1)\n",
    "\n",
    "(real_val, logical_val) = obj1.predict(test_data)\n",
    "\n",
    "print(real_val, logical_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.59982941] 1\n"
     ]
    }
   ],
   "source": [
    "test_data = np.array([12, 0])  # (예습, 복습) = (12, 0) => Pass (1)\n",
    "\n",
    "(real_val, logical_val) = obj1.predict(test_data)\n",
    "\n",
    "print(real_val, logical_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
